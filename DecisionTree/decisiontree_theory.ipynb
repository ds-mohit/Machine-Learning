{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b50e3dac",
   "metadata": {},
   "source": [
    "<img src=\"decisiontree_thoery.jpg\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f54a88d",
   "metadata": {},
   "source": [
    "```decision tree``` is build on ```cart and id3 ```\n",
    "\n",
    "cart is used for regression and id3 is used for classification\n",
    "\n",
    "cart is known as classification and regression tree and id3 is also known as  Iterative Dichotomiser 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9821f7f2",
   "metadata": {},
   "source": [
    "```root node --> decision node ---> leaf node```\n",
    "root node is target variable \n",
    "\n",
    "decision node is independent variable, for selecting decision node we required entropy and information gain\n",
    "\n",
    "leaf node is dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa81cbf",
   "metadata": {},
   "source": [
    "```information gain ```is defined as which feature give best split.\n",
    "\n",
    "and feature which has highest info gain is selected as decision node .\n",
    "\n",
    "```entropy``` is defined as impurity.\n",
    "\n",
    "and it helps in finding information gain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2777058a",
   "metadata": {},
   "source": [
    "<img src=\"more_info.jpg\" widht =100>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06351ea6",
   "metadata": {},
   "source": [
    "entropy = -p log (p)\n",
    "\n",
    "info gain = entropy(s)-entropy(s)\n",
    "\n",
    "<img src=\"formula.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4e6ab5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
